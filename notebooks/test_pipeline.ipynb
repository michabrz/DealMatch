{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DealMatch.trainer_unsupervised import Trainer\n",
    "from DealMatch.data_unsupervised import get_targets_data, get_investors_data, get_matching_keys, clean_targets, clean_investors\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.neighbors import NearestNeighbors, KNeighborsClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_targets_clean = pd.read_csv('../targets.csv', index_col=0).drop(columns='index')\n",
    "test = pd.read_excel('../DealMatch/targets_clean_test.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get X\n",
    "X = df_targets_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numerical pipeline --> no changes\n",
    "num_features = ['target_ebit','target_ebitda','target_revenue']\n",
    "num_transformer = Pipeline([('imputer', SimpleImputer(missing_values=np.nan, strategy='constant', fill_value=0)),\n",
    "                            ('scaler', RobustScaler())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom class transform sparse data from TFIDF to Dense so it fits the numerical transformation\n",
    "class DenseTransformer(TransformerMixin):\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None, **fit_params):\n",
    "        return X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf pipe --> included dense transformer\n",
    "tfidf_features = 'strs'\n",
    "tfidf_transformer = Pipeline([('tfidf', TfidfVectorizer()), ('dense', DenseTransformer())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full preproc\n",
    "preproc = ColumnTransformer(transformers=[\n",
    "            ('num_tr', num_transformer, num_features),\n",
    "            ('tfidf',tfidf_transformer, tfidf_features)\n",
    "        ], remainder='drop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1111, 4632)"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preproc.fit_transform(X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "#full pipe excluding model (had to take out the model because couldn't use attribute 'predict')\n",
    "full = Pipeline([('preproc', preproc),\n",
    "                                          ('pca',\n",
    "                                           PCA(0.95))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1111, 2)"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full.fit_transform(X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fitted preproc model -> to save\n",
    "preproc_fitted = full.fit(X)\n",
    "\n",
    "#transformed X to train nneighbors\n",
    "preproc_transformed = preproc_fitted.transform(X)\n",
    "\n",
    "#fitted model -> to save\n",
    "fitted_nn = NearestNeighbors(n_neighbors=10).fit(preproc_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.11123943, 0.27253504, 0.29032934, 0.45281042, 0.48279175,\n",
       "         0.48902642, 0.57433349, 0.60868525, 0.63310101, 0.65931131]]),\n",
       " array([[451, 648, 729,  72, 886, 877, 136, 893,  66, 319]]))"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform test data with preproc + pca pipeline\n",
    "test_transformed = preproc_fitted.transform(test)\n",
    "\n",
    "#run prediction on trained model\n",
    "fitted_nn.kneighbors(test_transformed)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "63305f572d39f1f057a29d6f90b97f50226f939806bf67798e7b1d2d4622b84a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('lewagon')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
