{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d4b89b6",
   "metadata": {},
   "source": [
    "# Packages imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e666316f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import string \n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth',None)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef99eaeb",
   "metadata": {},
   "source": [
    "# Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70f32413",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_deals_raw = pd.read_excel('../raw_data/deals_raw.xlsx')\n",
    "key_match = pd.read_excel('../raw_data/new_keywords.xlsx')\n",
    "invest_key = pd.read_excel('../raw_data/invest_profile_keywords.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4676c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "matching_table = pd.read_excel('../raw_data/matching_table.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f9e081",
   "metadata": {},
   "source": [
    "# Preprocessing of DataFrames and training Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af371fb5",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b23d0eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuations(text):\n",
    "    for punctuation in string.punctuation:\n",
    "        text = text.replace(punctuation, '')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e13a090",
   "metadata": {},
   "source": [
    "## Targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a543ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3278/944302302.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_deals_raw_work.dropna(subset='target_name',inplace=True)\n",
      "/tmp/ipykernel_3278/944302302.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_deals_raw_work['strs'] = df_deals_raw_work['strs'].str.replace(',',' ')\n",
      "/tmp/ipykernel_3278/944302302.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_deals_raw_work[['target_ebit','target_revenue']] = df_deals_raw_work[['target_ebit','target_revenue']].replace(np.nan, 0)\n",
      "/tmp/ipykernel_3278/944302302.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_deals_raw_work['strs'] = df_deals_raw_work['strs'].apply(remove_punctuations)\n",
      "/tmp/ipykernel_3278/944302302.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_deals_raw_work['strs'] = df_deals_raw_work['strs'].apply(lambda x: x.lower())\n"
     ]
    }
   ],
   "source": [
    "rel_columns = ['target_name', 'name', 'target_ebit', 'target_ebitda', 'target_revenue']\n",
    "\n",
    "dict_2 = {}\n",
    "dict_3 = {}\n",
    "dict_4 = {}\n",
    "\n",
    "for i in df_deals_raw['target_name'].unique():\n",
    "    df_rel = df_deals_raw.loc[df_deals_raw['target_name'] == i]\n",
    "    set_rel_2 = set(df_rel['name_de.2'])\n",
    "    dict_2[i] = set_rel_2\n",
    "\n",
    "    set_rel_3 = set(df_rel['name_de.3'])\n",
    "    dict_3[i] = set_rel_3\n",
    "\n",
    "    set_rel_4 = set(df_rel['name_de.4'])\n",
    "    dict_4[i] = set_rel_4\n",
    "    \n",
    "df_deals_raw_rel = df_deals_raw[rel_columns].copy().drop_duplicates(subset = 'name')\n",
    "df_deals_raw_rel['2'] = df_deals_raw_rel.target_name.apply(lambda x: dict_2.get(x))\n",
    "df_deals_raw_rel['3'] = df_deals_raw_rel.target_name.apply(lambda x: dict_3.get(x))\n",
    "df_deals_raw_rel['4'] = df_deals_raw_rel.target_name.apply(lambda x: dict_4.get(x))\n",
    "df_deals_raw_rel['comb'] = df_deals_raw_rel.apply(lambda x: set.union(x['2'], x['3'], x['4']), axis = 1)\n",
    "df_deals_raw_rel['comb_str'] = df_deals_raw_rel.comb.apply(lambda x: list(map(str, x)))\n",
    "df_deals_raw_rel['strs'] = df_deals_raw_rel.comb_str.apply(lambda x:  \",\".join(list(x)))\n",
    "df_deals_raw_rel.drop_duplicates(subset='target_name', keep=\"first\",inplace=True)\n",
    "\n",
    "df_deals_raw_work = df_deals_raw_rel[['target_name','target_ebit','target_revenue','strs']]\n",
    "\n",
    "df_deals_raw_work.dropna(subset='target_name',inplace=True)\n",
    "df_deals_raw_work['strs'] = df_deals_raw_work['strs'].str.replace(',',' ')\n",
    "df_deals_raw_work[['target_ebit','target_revenue']] = df_deals_raw_work[['target_ebit','target_revenue']].replace(np.nan, 0)\n",
    "df_deals_raw_work.reset_index().drop('index',axis=1)\n",
    "\n",
    "df_deals_raw_work['strs'] = df_deals_raw_work['strs'].apply(remove_punctuations) \n",
    "df_deals_raw_work['strs'] = df_deals_raw_work['strs'].apply(lambda x: x.lower())\n",
    "\n",
    "stop_words = set(stopwords.words('german')) \n",
    "\n",
    "for name_de in df_deals_raw_work['strs']:    \n",
    "    word_tokens = word_tokenize(name_de) \n",
    "    name_de = [w for w in word_tokens if not w in stop_words] \n",
    "    \n",
    "scaler = MinMaxScaler()\n",
    "df_deals_raw_work_fin = pd.DataFrame(scaler.fit_transform(\n",
    "                        df_deals_raw_work.drop(columns=['target_name','strs'])),\n",
    "                                    columns=['target_ebit', 'target_revenue'])\n",
    "\n",
    "df_deals_raw_work_fin = df_deals_raw_work_fin.reset_index().drop('index',axis=1)\n",
    "\n",
    "df_deals_raw_work = df_deals_raw_work.reset_index().drop('index',axis=1)\n",
    "df_deals_raw_work1 = pd.concat([df_deals_raw_work.drop(columns=['target_ebit','target_revenue']), \n",
    "                                df_deals_raw_work_fin], axis=1)\n",
    "\n",
    "vec_tf_target = TfidfVectorizer()\n",
    "x_tf_target = vec_tf_target.fit_transform(df_deals_raw_work1['strs'])\n",
    "df_wrds_tf_target = pd.DataFrame(x_tf_target.toarray(), columns=vec_tf_target.get_feature_names_out())\n",
    "df_tf_target = pd.concat([df_deals_raw_work1, df_wrds_tf_target], axis=1)\n",
    "df_tf_target.drop('strs', axis=1, inplace=True)\n",
    "df_tf_target_4pca = df_tf_target.drop('target_name',axis=1)\n",
    "\n",
    "pca_tf_target = PCA()\n",
    "df_tf_target_pca = pca_tf_target.fit_transform(df_tf_target_4pca)\n",
    "total_explained_variance = pca_tf_target.explained_variance_ratio_.cumsum()\n",
    "n_over_95 = len(total_explained_variance[total_explained_variance>=.95])\n",
    "n_to_reach_95 = df_tf_target_pca.shape[1] - n_over_95\n",
    "pca_tf_target = PCA(n_components=n_to_reach_95)\n",
    "df_tf_target_pca = pca_tf_target.fit_transform(df_tf_target_4pca)\n",
    "\n",
    "nn_target_tf_pca = NearestNeighbors(n_neighbors=10).fit(df_tf_target_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a648f373",
   "metadata": {},
   "source": [
    "## Investors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d9b9f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "invest_key['name_de'] = invest_key['name_de'].replace(dict(zip(key_match.name_de,key_match.new_keyword)))\n",
    "invest_key_small = invest_key[['name','name_de']]\n",
    "invest_key_concat = invest_key_small.astype(str).groupby('name').agg({'name_de':', '.join})\n",
    "    \n",
    "invest_key_concat1 = invest_key_concat['name_de'].str.replace('nan','').reset_index()\n",
    "invest_key_concat1['name_de'] = invest_key_concat1['name_de'].apply(remove_punctuations)        \n",
    "invest_key_concat1['name_de'].replace(r'^\\s*$',np.nan,regex=True,inplace=True)\n",
    "invest_key_concat1 = invest_key_concat1.dropna().reset_index().drop('index',axis=1)\n",
    "invest_key_concat1['name_de'] = invest_key_concat1['name_de'].apply(lambda x: x.lower())\n",
    "\n",
    "stop_words = set(stopwords.words('german')) \n",
    "\n",
    "for name_de in invest_key_concat1['name_de']:    \n",
    "    word_tokens = word_tokenize(name_de) \n",
    "    name_de = [w for w in word_tokens if not w in stop_words] \n",
    "    \n",
    "vec_tf_key = TfidfVectorizer()\n",
    "x_tf_key = vec_tf_key.fit_transform(invest_key_concat1['name_de'])\n",
    "df_wrds_tf_key = pd.DataFrame(x_tf_key.toarray(), columns=vec_tf_key.get_feature_names_out())\n",
    "df_tf_key = pd.concat([invest_key_concat1, df_wrds_tf_key], axis=1)\n",
    "df_tf_key.drop('name_de', axis=1, inplace=True)\n",
    "df_tf_key_4pca = df_tf_key.drop('name',axis=1)\n",
    "\n",
    "pca_tf_key = PCA()\n",
    "df_tf_key_pca = pca_tf_key.fit_transform(df_tf_key_4pca)\n",
    "total_explained_variance = pca_tf_key.explained_variance_ratio_.cumsum()\n",
    "n_over_95 = len(total_explained_variance[total_explained_variance>=.95])\n",
    "n_to_reach_95 = df_tf_key_pca.shape[1] - n_over_95\n",
    "pca_tf_key = PCA(n_components=n_to_reach_95)\n",
    "df_tf_key_pca = pca_tf_key.fit_transform(df_tf_key_4pca)\n",
    "\n",
    "qty_of_nn = 5\n",
    "nn_key_tf_pca = NearestNeighbors(n_neighbors=qty_of_nn).fit(df_tf_key_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb0ea2e",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "759dcd2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3278/3289453189.py:57: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  if invest_key_concat1['name'].str.contains(investor).any():\n",
      "/tmp/ipykernel_3278/3289453189.py:66: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  if invest_key_concat1['name'].str.contains(investor).any():\n"
     ]
    }
   ],
   "source": [
    "target_pred = df_deals_raw_work1[df_deals_raw_work1['target_name']=='Maybach-Luxury']\n",
    "\n",
    "target_pred_scapled = pd.DataFrame(scaler.transform(target_pred.drop(columns=['target_name','strs'])),\n",
    "                                  columns=['target_ebit', 'target_revenue'])\n",
    "\n",
    "tx_to_pred = vec_tf_target.transform(target_pred['strs'])\n",
    "df_target_pred_wrds = pd.DataFrame(tx_to_pred.toarray(),columns=vec_tf_target.get_feature_names_out())\n",
    "df_target_pred = df_target_pred_wrds.copy()\n",
    "df_target_pred.insert(0,'target_ebit',target_pred_scapled['target_ebit'])\n",
    "df_target_pred.insert(1,'target_revenue',target_pred_scapled['target_revenue'])\n",
    "df_target_pred_pca = pca_tf_target.transform(df_target_pred)\n",
    "\n",
    "nn_targets = nn_target_tf_pca.kneighbors(df_target_pred_pca)\n",
    "\n",
    "name = []\n",
    "description = []\n",
    "distance = []\n",
    "\n",
    "\n",
    "\n",
    "for x,y in zip(nn_targets[1][0],nn_targets[0][0]):\n",
    "    name.append(df_deals_raw_work1['target_name'].iloc[x])\n",
    "    description.append(df_deals_raw_work1['strs'].iloc[x])\n",
    "    distance.append(y)\n",
    "    \n",
    "    \n",
    "df_companies = pd.DataFrame({'name':name,\n",
    "               'description':description,\n",
    "               'distance':distance})\n",
    "\n",
    "\n",
    "matching_investors = []\n",
    "matching_target = []\n",
    "matching_distance = []\n",
    "for company in df_companies['name']:\n",
    "    next_investor = matching_table[(matching_table['target_name']==company) & (matching_table['deal_stage_id']==4)]['comp_name'].tolist()\n",
    "    matching_investors+=next_investor\n",
    "    matching_target+=len(next_investor)*[company]\n",
    "    next_distance = df_companies[df_companies['name']==company]['distance'].tolist()\n",
    "    matching_distance+=len(next_investor)*next_distance\n",
    "df_match_investors = pd.DataFrame({'investors':matching_investors,'targets':matching_target,'distance':matching_distance})\n",
    "\n",
    "\n",
    "if len(df_match_investors['investors'].unique())>=10:\n",
    "    best_investors = df_match_investors['investors'].unique()[:10].tolist()\n",
    "else:\n",
    "    best_investors = df_match_investors['investors'].unique().tolist()\n",
    "    \n",
    "name_investor = []\n",
    "description_investor = []\n",
    "distance_investor_investor = []\n",
    "distance_target_target = []\n",
    "\n",
    "\n",
    "for investor in best_investors:\n",
    "    name_investor.append(investor)\n",
    "    if invest_key_concat1['name'].str.contains(investor).any():\n",
    "        description_investor.append(invest_key_concat1[invest_key_concat1['name']==investor]['name_de'].to_list()[0])\n",
    "    else:\n",
    "        description_investor.append('Investor not in the list')\n",
    "    distance_investor_investor.append(0)\n",
    "    distance_target_target.append(df_match_investors[df_match_investors['investors']==investor]['distance'].min())\n",
    "\n",
    "\n",
    "for investor in best_investors:\n",
    "    if invest_key_concat1['name'].str.contains(investor).any():\n",
    "        first_distance = df_match_investors[df_match_investors['investors']==investor]['distance'].min()\n",
    "        to_pred = invest_key_concat1[invest_key_concat1['name']==investor]\n",
    "        x_to_pred = vec_tf_key.transform(to_pred['name_de'])\n",
    "        df_pred_wrds = pd.DataFrame(x_to_pred.toarray(),columns=vec_tf_key.get_feature_names_out())\n",
    "        df_pred = pd.concat([to_pred,df_pred_wrds], axis=1)\n",
    "        df_pred.drop('name_de', axis=1, inplace=True)\n",
    "        df_pred_4pca = df_pred.drop('name',axis=1).dropna()\n",
    "        df_pred_pca = pca_tf_key.transform(df_pred_4pca)\n",
    "\n",
    "        nn_investors = nn_key_tf_pca.kneighbors(df_pred_pca)\n",
    "\n",
    "\n",
    "        for x,y in zip(nn_investors[1][0],nn_investors[0][0]):\n",
    "            name_investor.append(invest_key_concat1['name'].iloc[x])\n",
    "            description_investor.append(invest_key_concat1['name_de'].iloc[x])\n",
    "            distance_investor_investor.append(y)\n",
    "            distance_target_target.append(first_distance)\n",
    "        \n",
    "df_investors = pd.DataFrame({'name':name_investor,\n",
    "               'description':description_investor,\n",
    "               'distance_investor<=>investor':distance_investor_investor,\n",
    "                'distance_target<=>target':distance_target_target,\n",
    "                'distance_target<=>investor': [a+b for a,b in zip(distance_investor_investor,distance_target_target)]})\n",
    "\n",
    "df_investors_sorted = df_investors.sort_values('distance_target<=>investor')\n",
    "df_investors_sorted.reset_index(inplace=True)\n",
    "df_investors_sorted.drop('index',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a7aef55",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>distance_investor&lt;=&gt;investor</th>\n",
       "      <th>distance_target&lt;=&gt;target</th>\n",
       "      <th>distance_target&lt;=&gt;investor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Eso Capital UK Ltd</td>\n",
       "      <td>zubehör glas handel luxusgüter lizenz sme fizierung</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002793</td>\n",
       "      <td>0.002793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Eso Capital UK Ltd</td>\n",
       "      <td>zubehör glas handel luxusgüter lizenz sme fizierung</td>\n",
       "      <td>0.020072</td>\n",
       "      <td>0.002793</td>\n",
       "      <td>0.022865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aprima</td>\n",
       "      <td>personaldienstleister sme</td>\n",
       "      <td>0.971242</td>\n",
       "      <td>0.002793</td>\n",
       "      <td>0.974035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CIT Leveraged Finance</td>\n",
       "      <td>fizierung fizierung  fizierung übernahme</td>\n",
       "      <td>1.017259</td>\n",
       "      <td>0.002793</td>\n",
       "      <td>1.020052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Essence Capital</td>\n",
       "      <td>bewertung fizierung  strategic advisory fond</td>\n",
       "      <td>1.017392</td>\n",
       "      <td>0.002793</td>\n",
       "      <td>1.020185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    name                                          description  \\\n",
       "0     Eso Capital UK Ltd  zubehör glas handel luxusgüter lizenz sme fizierung   \n",
       "1     Eso Capital UK Ltd  zubehör glas handel luxusgüter lizenz sme fizierung   \n",
       "2                 Aprima                            personaldienstleister sme   \n",
       "3  CIT Leveraged Finance             fizierung fizierung  fizierung übernahme   \n",
       "4        Essence Capital         bewertung fizierung  strategic advisory fond   \n",
       "\n",
       "   distance_investor<=>investor  distance_target<=>target  \\\n",
       "0                      0.000000                  0.002793   \n",
       "1                      0.020072                  0.002793   \n",
       "2                      0.971242                  0.002793   \n",
       "3                      1.017259                  0.002793   \n",
       "4                      1.017392                  0.002793   \n",
       "\n",
       "   distance_target<=>investor  \n",
       "0                    0.002793  \n",
       "1                    0.022865  \n",
       "2                    0.974035  \n",
       "3                    1.020052  \n",
       "4                    1.020185  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_investors_sorted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5e36ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4b19a0fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model_investors.joblib']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(nn_target_tf_pca,'model_investors.joblib')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "433a14f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_targets = joblib.load('model_investors.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e73e8ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../DealMatch/target_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0093ac51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pawel/.pyenv/versions/3.8.12/envs/dealmatch/lib/python3.8/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but NearestNeighbors was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '876 Berlin'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [20]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m nearest_targets \u001b[38;5;241m=\u001b[39m \u001b[43mpipe_targets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkneighbors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/dealmatch/lib/python3.8/site-packages/sklearn/neighbors/_base.py:717\u001b[0m, in \u001b[0;36mKNeighborsMixin.kneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    715\u001b[0m         X \u001b[38;5;241m=\u001b[39m _check_precomputed(X)\n\u001b[1;32m    716\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 717\u001b[0m         X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    718\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    719\u001b[0m     query_is_train \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/dealmatch/lib/python3.8/site-packages/sklearn/base.py:566\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    564\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation should be done on X, y or both.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    565\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 566\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    567\u001b[0m     out \u001b[38;5;241m=\u001b[39m X\n\u001b[1;32m    568\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/dealmatch/lib/python3.8/site-packages/sklearn/utils/validation.py:746\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    744\u001b[0m         array \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mastype(dtype, casting\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munsafe\u001b[39m\u001b[38;5;124m\"\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    745\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 746\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    749\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[1;32m    750\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/dealmatch/lib/python3.8/site-packages/pandas/core/generic.py:2072\u001b[0m, in \u001b[0;36mNDFrame.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   2071\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype: npt\u001b[38;5;241m.\u001b[39mDTypeLike \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[0;32m-> 2072\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '876 Berlin'"
     ]
    }
   ],
   "source": [
    "nearest_targets = pipe_targets.kneighbors(df,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "30c6da90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.00279297, 1.1119553 , 1.11658997, 1.13265075, 1.13274887,\n",
       "         1.15757688, 1.16336   , 1.17447485, 1.179343  , 1.18643689]]),\n",
       " array([[  75,   74,  500, 1035, 1058,  843,  858,  588, 1008,  366]]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a06db0aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_name</th>\n",
       "      <th>strs</th>\n",
       "      <th>target_ebit</th>\n",
       "      <th>target_revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sun [Target]</td>\n",
       "      <td>energie solar solarenergie pv energie photovoltaik</td>\n",
       "      <td>0.617200</td>\n",
       "      <td>0.000140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Supple [Target]</td>\n",
       "      <td>solarenergie pv sonne solar energie erneuerbare energie  sonstige energie fresnel photovoltaik</td>\n",
       "      <td>0.617200</td>\n",
       "      <td>0.028986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SPH Sustainable Process Heat GmbH</td>\n",
       "      <td>abwärme industrielle produkte  dienstleistungen pumpen und armaturen wärmepumpentechnologie prozesswärme energieeffizient pumpen niedertemperatur</td>\n",
       "      <td>0.607248</td>\n",
       "      <td>0.000355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SUMMIQ AG</td>\n",
       "      <td>infrastrukturfonds finanzdienstleistungen stadtwerkegruppen energieversorger finanzdienstleistungen  sonstige stadtwerke</td>\n",
       "      <td>0.617200</td>\n",
       "      <td>0.000140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KSW Bioenergie GmbH</td>\n",
       "      <td>erneuerbare energie bioenergie bioenergie biomasse co2 kraftwerk energie nachhaltigkeit energie biotreibstoff</td>\n",
       "      <td>0.617200</td>\n",
       "      <td>0.000140</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         target_name  \\\n",
       "0                       Sun [Target]   \n",
       "1                    Supple [Target]   \n",
       "2  SPH Sustainable Process Heat GmbH   \n",
       "3                          SUMMIQ AG   \n",
       "4                KSW Bioenergie GmbH   \n",
       "\n",
       "                                                                                                                                                strs  \\\n",
       "0                                                                                                 energie solar solarenergie pv energie photovoltaik   \n",
       "1                                                     solarenergie pv sonne solar energie erneuerbare energie  sonstige energie fresnel photovoltaik   \n",
       "2  abwärme industrielle produkte  dienstleistungen pumpen und armaturen wärmepumpentechnologie prozesswärme energieeffizient pumpen niedertemperatur   \n",
       "3                           infrastrukturfonds finanzdienstleistungen stadtwerkegruppen energieversorger finanzdienstleistungen  sonstige stadtwerke   \n",
       "4                                      erneuerbare energie bioenergie bioenergie biomasse co2 kraftwerk energie nachhaltigkeit energie biotreibstoff   \n",
       "\n",
       "   target_ebit  target_revenue  \n",
       "0     0.617200        0.000140  \n",
       "1     0.617200        0.028986  \n",
       "2     0.607248        0.000355  \n",
       "3     0.617200        0.000140  \n",
       "4     0.617200        0.000140  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_deals_raw_work1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a3989a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "137px",
    "width": "378px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
